2025-09-20 08:39:45,378 - loralab.config.config_loader - INFO - Loaded configuration from loralab\config\gemma_config.yaml
2025-09-20 08:39:45,378 - loralab.utils.output_manager - INFO - Output manager initialized at: lora_runs_gemma\run_20250920_083945
2025-09-20 08:39:45,378 - loralab.evolution.evolutionary_trainer - INFO - Using unsloth backend
2025-09-20 08:39:45,381 - loralab.utils.output_manager - INFO - Config saved to: lora_runs_gemma\run_20250920_083945\config\config.yaml
2025-09-20 08:39:45,498 - loralab.core.unsloth_manager - INFO - Loading Unsloth model: unsloth/gemma-3-270m-it with none quantization
2025-09-20 08:39:45,498 - loralab.core.unsloth_manager - INFO - Using configured dtype: float16
2025-09-20 08:39:50,668 - loralab.core.unsloth_manager - INFO - Applied chat template: gemma3
2025-09-20 08:39:50,670 - loralab.datasets.dataset_loader - INFO - Loading dataset: gsm8k
2025-09-20 08:39:50,670 - loralab.datasets.dataset_loader - INFO - Fetching gsm8k from HuggingFace...
2025-09-20 08:39:54,141 - loralab.datasets.dataset_loader - INFO - Loaded 2000 training and 100 evaluation examples
2025-09-20 08:39:54,142 - loralab.evolution.evolutionary_trainer - INFO - 
================================================================================
2025-09-20 08:39:54,142 - loralab.evolution.evolutionary_trainer - INFO - STARTING EVOLUTIONARY OPTIMIZATION
2025-09-20 08:39:54,142 - loralab.evolution.evolutionary_trainer - INFO - ================================================================================
2025-09-20 08:39:54,142 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 0209a7c3)
2025-09-20 08:39:54,142 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr5e-05 (hash: 7b13c093)
2025-09-20 08:39:54,142 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: cc916834)
2025-09-20 08:39:54,142 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 3d608301)
2025-09-20 08:39:54,142 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr1e-04 (hash: 8054b9a9)
2025-09-20 08:39:54,143 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: f1ee4565)
2025-09-20 08:39:54,143 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr5e-05 (hash: baf5e86d)
2025-09-20 08:39:54,143 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr2e-04 (hash: c1bea809)
2025-09-20 08:39:54,143 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr1e-04 (hash: 239a06ae)
2025-09-20 08:39:54,143 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 0ba659fd)
2025-09-20 08:39:54,143 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr2e-04 (hash: a448aa76)
2025-09-20 08:39:54,143 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 2dec99bc)
2025-09-20 08:39:55,189 - loralab.core.unsloth_manager - INFO - LoRA variant created with Unsloth optimizations:
2025-09-20 08:39:55,189 - loralab.core.unsloth_manager - INFO -   Rank: 8, Alpha: 8 (multiplier: 1)
2025-09-20 08:39:55,190 - loralab.core.unsloth_manager - INFO -   Trainable params: 737,280 (0.27%)
2025-09-20 08:39:55,190 - loralab.core.unsloth_manager - INFO -   Gradient checkpointing: unsloth
2025-09-20 08:39:55,190 - loralab.core.unsloth_manager - INFO -   RSLoRA: True
2025-09-20 08:39:55,190 - loralab.evolution.evolutionary_trainer - INFO - Train data has 2000 total examples
2025-09-20 08:39:55,190 - loralab.evolution.evolutionary_trainer - INFO - Requesting 10 format examples
2025-09-20 08:39:55,190 - loralab.evolution.evolutionary_trainer - INFO - Actually got 10 format examples
2025-09-20 08:39:55,190 - loralab.evolution.evolutionary_trainer - INFO - Pre-training on format with 10 examples for 1 epochs
2025-09-20 08:39:55,190 - loralab.training.grpo_trainer - INFO - Pre-training model on format examples...
2025-09-20 08:39:55,227 - loralab.training.grpo_trainer - INFO - Pre-training configuration:
2025-09-20 08:39:55,227 - loralab.training.grpo_trainer - INFO -   - Examples: 10
2025-09-20 08:39:55,228 - loralab.training.grpo_trainer - INFO -   - Batch size: 1
2025-09-20 08:39:55,228 - loralab.training.grpo_trainer - INFO -   - Gradient accumulation: 2
2025-09-20 08:39:55,228 - loralab.training.grpo_trainer - INFO -   - Effective batch size: 2
2025-09-20 08:39:55,228 - loralab.training.grpo_trainer - INFO -   - Epochs: 1
2025-09-20 08:39:55,228 - loralab.training.grpo_trainer - INFO -   - Expected training steps: 10
2025-09-20 08:39:55,229 - loralab.training.grpo_trainer - INFO - Created pre-training dataset with 10 examples
2025-09-20 08:40:00,846 - loralab.training.grpo_trainer - INFO - Pre-training completed with final loss: 2.8855
2025-09-20 08:40:00,846 - loralab.training.grpo_trainer - INFO - Starting GRPO training for gen0_r8_lr1e-04
2025-09-20 08:59:44,770 - loralab.training.grpo_trainer - INFO - GRPO training completed for gen0_r8_lr1e-04
2025-09-20 08:59:44,770 - loralab.training.grpo_trainer - INFO -   Final loss: 0.4499
2025-09-20 08:59:44,770 - loralab.training.grpo_trainer - INFO -   Average reward: 0.0000
2025-09-20 09:00:59,508 - loralab.evolution.fitness_evaluator - INFO - Evaluation complete for gen0_r8_lr1e-04: Accuracy=7.00%, Perplexity=695.59
2025-09-20 09:00:59,510 - loralab.core.lora_factory - INFO - Saved variant to lora_runs_gemma\run_20250920_083945\checkpoints\generations\gen0\gen0_r8_lr1e-04\config.json
2025-09-20 09:01:02,645 - loralab.core.unsloth_manager - INFO - LoRA variant created with Unsloth optimizations:
2025-09-20 09:01:02,646 - loralab.core.unsloth_manager - INFO -   Rank: 16, Alpha: 16 (multiplier: 1)
2025-09-20 09:01:02,646 - loralab.core.unsloth_manager - INFO -   Trainable params: 3,796,992 (1.40%)
2025-09-20 09:01:02,646 - loralab.core.unsloth_manager - INFO -   Gradient checkpointing: unsloth
2025-09-20 09:01:02,646 - loralab.core.unsloth_manager - INFO -   RSLoRA: False
2025-09-20 09:01:02,646 - loralab.evolution.evolutionary_trainer - INFO - Train data has 2000 total examples
2025-09-20 09:01:02,646 - loralab.evolution.evolutionary_trainer - INFO - Requesting 10 format examples
2025-09-20 09:01:02,646 - loralab.evolution.evolutionary_trainer - INFO - Actually got 10 format examples
2025-09-20 09:01:02,646 - loralab.evolution.evolutionary_trainer - INFO - Pre-training on format with 10 examples for 1 epochs
2025-09-20 09:01:02,646 - loralab.training.grpo_trainer - INFO - Pre-training model on format examples...
2025-09-20 09:01:02,689 - loralab.training.grpo_trainer - INFO - Pre-training configuration:
2025-09-20 09:01:02,690 - loralab.training.grpo_trainer - INFO -   - Examples: 10
2025-09-20 09:01:02,690 - loralab.training.grpo_trainer - INFO -   - Batch size: 1
2025-09-20 09:01:02,690 - loralab.training.grpo_trainer - INFO -   - Gradient accumulation: 2
2025-09-20 09:01:02,690 - loralab.training.grpo_trainer - INFO -   - Effective batch size: 2
2025-09-20 09:01:02,690 - loralab.training.grpo_trainer - INFO -   - Epochs: 1
2025-09-20 09:01:02,690 - loralab.training.grpo_trainer - INFO -   - Expected training steps: 10
2025-09-20 09:01:02,692 - loralab.training.grpo_trainer - INFO - Created pre-training dataset with 10 examples
2025-09-20 09:01:11,862 - loralab.training.grpo_trainer - INFO - Pre-training completed with final loss: 2.8969
2025-09-20 09:01:11,863 - loralab.training.grpo_trainer - INFO - Starting GRPO training for gen0_r16_lr5e-05
2025-09-20 09:18:24,899 - loralab.training.grpo_trainer - INFO - GRPO training completed for gen0_r16_lr5e-05
2025-09-20 09:18:24,899 - loralab.training.grpo_trainer - INFO -   Final loss: 0.4912
2025-09-20 09:18:24,899 - loralab.training.grpo_trainer - INFO -   Average reward: 0.0000
2025-09-20 09:19:35,894 - loralab.evolution.fitness_evaluator - INFO - Evaluation complete for gen0_r16_lr5e-05: Accuracy=5.00%, Perplexity=693.95
2025-09-20 09:19:35,895 - loralab.core.lora_factory - INFO - Saved variant to lora_runs_gemma\run_20250920_083945\checkpoints\generations\gen0\gen0_r16_lr5e-05\config.json
2025-09-20 09:19:39,365 - loralab.core.unsloth_manager - INFO - LoRA variant created with Unsloth optimizations:
2025-09-20 09:19:39,365 - loralab.core.unsloth_manager - INFO -   Rank: 8, Alpha: 16 (multiplier: 2)
2025-09-20 09:19:39,365 - loralab.core.unsloth_manager - INFO -   Trainable params: 3,059,712 (1.13%)
2025-09-20 09:19:39,365 - loralab.core.unsloth_manager - INFO -   Gradient checkpointing: unsloth
2025-09-20 09:19:39,365 - loralab.core.unsloth_manager - INFO -   RSLoRA: True
2025-09-20 09:19:39,365 - loralab.evolution.evolutionary_trainer - INFO - Train data has 2000 total examples
2025-09-20 09:19:39,365 - loralab.evolution.evolutionary_trainer - INFO - Requesting 10 format examples
2025-09-20 09:19:39,365 - loralab.evolution.evolutionary_trainer - INFO - Actually got 10 format examples
2025-09-20 09:19:39,366 - loralab.evolution.evolutionary_trainer - INFO - Pre-training on format with 10 examples for 1 epochs
2025-09-20 09:19:39,366 - loralab.training.grpo_trainer - INFO - Pre-training model on format examples...
2025-09-20 09:19:39,402 - loralab.training.grpo_trainer - INFO - Pre-training configuration:
2025-09-20 09:19:39,402 - loralab.training.grpo_trainer - INFO -   - Examples: 10
2025-09-20 09:19:39,403 - loralab.training.grpo_trainer - INFO -   - Batch size: 1
2025-09-20 09:19:39,403 - loralab.training.grpo_trainer - INFO -   - Gradient accumulation: 2
2025-09-20 09:19:39,403 - loralab.training.grpo_trainer - INFO -   - Effective batch size: 2
2025-09-20 09:19:39,403 - loralab.training.grpo_trainer - INFO -   - Epochs: 1
2025-09-20 09:19:39,403 - loralab.training.grpo_trainer - INFO -   - Expected training steps: 10
2025-09-20 09:19:39,405 - loralab.training.grpo_trainer - INFO - Created pre-training dataset with 10 examples
2025-09-20 09:19:42,267 - loralab.training.grpo_trainer - INFO - Pre-training completed with final loss: 2.5068
2025-09-20 09:19:42,268 - loralab.training.grpo_trainer - INFO - Starting GRPO training for gen0_r8_lr1e-04
2025-09-20 09:25:00,995 - loralab.config.config_loader - INFO - Loaded configuration from loralab\config\gemma_config.yaml
2025-09-20 09:25:00,995 - loralab.utils.output_manager - INFO - Output manager initialized at: lora_runs_gemma\run_20250920_092500
2025-09-20 09:25:00,996 - loralab.evolution.evolutionary_trainer - INFO - Using unsloth backend
2025-09-20 09:25:00,998 - loralab.utils.output_manager - INFO - Config saved to: lora_runs_gemma\run_20250920_092500\config\config.yaml
2025-09-20 09:25:01,113 - loralab.core.unsloth_manager - INFO - Loading Unsloth model: unsloth/gemma-3-270m-it with none quantization
2025-09-20 09:25:01,113 - loralab.core.unsloth_manager - INFO - Using configured dtype: float16
2025-09-20 09:25:06,494 - loralab.core.unsloth_manager - INFO - Applied chat template: gemma3
2025-09-20 09:25:06,495 - loralab.datasets.dataset_loader - INFO - Loading dataset: gsm8k
2025-09-20 09:25:06,496 - loralab.datasets.dataset_loader - INFO - Fetching gsm8k from HuggingFace...
2025-09-20 09:25:09,950 - loralab.datasets.dataset_loader - INFO - Loaded 2000 training and 100 evaluation examples
2025-09-20 09:25:09,951 - loralab.evolution.evolutionary_trainer - INFO - 
================================================================================
2025-09-20 09:25:09,951 - loralab.evolution.evolutionary_trainer - INFO - STARTING EVOLUTIONARY OPTIMIZATION
2025-09-20 09:25:09,951 - loralab.evolution.evolutionary_trainer - INFO - ================================================================================
2025-09-20 09:25:09,952 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 0209a7c3)
2025-09-20 09:25:09,952 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr5e-05 (hash: 7b13c093)
2025-09-20 09:25:09,952 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: cc916834)
2025-09-20 09:25:09,952 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 3d608301)
2025-09-20 09:25:09,953 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr1e-04 (hash: 8054b9a9)
2025-09-20 09:25:09,953 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: f1ee4565)
2025-09-20 09:25:09,953 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr5e-05 (hash: baf5e86d)
2025-09-20 09:25:09,953 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr2e-04 (hash: c1bea809)
2025-09-20 09:25:09,953 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr1e-04 (hash: 239a06ae)
2025-09-20 09:25:09,953 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 0ba659fd)
2025-09-20 09:25:09,953 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr2e-04 (hash: a448aa76)
2025-09-20 09:25:09,954 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 2dec99bc)
2025-09-20 09:25:11,039 - loralab.core.unsloth_manager - INFO - LoRA variant created with Unsloth optimizations:
2025-09-20 09:25:11,040 - loralab.core.unsloth_manager - INFO -   Rank: 8, Alpha: 8 (multiplier: 1)
2025-09-20 09:25:11,040 - loralab.core.unsloth_manager - INFO -   Trainable params: 737,280 (0.27%)
2025-09-20 09:25:11,040 - loralab.core.unsloth_manager - INFO -   Gradient checkpointing: unsloth
2025-09-20 09:25:11,040 - loralab.core.unsloth_manager - INFO -   RSLoRA: True
2025-09-20 09:25:11,040 - loralab.evolution.evolutionary_trainer - INFO - Train data has 2000 total examples
2025-09-20 09:25:11,041 - loralab.evolution.evolutionary_trainer - INFO - Requesting 5 format examples
2025-09-20 09:25:11,041 - loralab.evolution.evolutionary_trainer - INFO - Actually got 5 format examples
2025-09-20 09:25:11,041 - loralab.evolution.evolutionary_trainer - INFO - Pre-training on format with 5 examples for 1 epochs
2025-09-20 09:25:11,041 - loralab.training.grpo_trainer - INFO - Pre-training model on format examples...
2025-09-20 09:25:11,075 - loralab.training.grpo_trainer - INFO - Pre-training configuration:
2025-09-20 09:25:11,076 - loralab.training.grpo_trainer - INFO -   - Examples: 5
2025-09-20 09:25:11,076 - loralab.training.grpo_trainer - INFO -   - Batch size: 1
2025-09-20 09:25:11,076 - loralab.training.grpo_trainer - INFO -   - Gradient accumulation: 2
2025-09-20 09:25:11,076 - loralab.training.grpo_trainer - INFO -   - Effective batch size: 2
2025-09-20 09:25:11,076 - loralab.training.grpo_trainer - INFO -   - Epochs: 1
2025-09-20 09:25:11,076 - loralab.training.grpo_trainer - INFO -   - Expected training steps: 5
2025-09-20 09:25:11,078 - loralab.training.grpo_trainer - INFO - Created pre-training dataset with 5 examples
2025-09-20 09:25:17,737 - loralab.training.grpo_trainer - INFO - Pre-training completed with final loss: 2.8983
2025-09-20 09:25:17,737 - loralab.training.grpo_trainer - INFO - Starting GRPO training for gen0_r8_lr1e-04
2025-09-20 09:29:05,254 - loralab.config.config_loader - INFO - Loaded configuration from loralab\config\gemma_config.yaml
2025-09-20 09:29:05,255 - loralab.utils.output_manager - INFO - Output manager initialized at: lora_runs_gemma\run_20250920_092905
2025-09-20 09:29:05,255 - loralab.evolution.evolutionary_trainer - INFO - Using unsloth backend
2025-09-20 09:29:05,258 - loralab.utils.output_manager - INFO - Config saved to: lora_runs_gemma\run_20250920_092905\config\config.yaml
2025-09-20 09:29:05,370 - loralab.core.unsloth_manager - INFO - Loading Unsloth model: unsloth/gemma-3-270m-it with none quantization
2025-09-20 09:29:05,370 - loralab.core.unsloth_manager - INFO - Using configured dtype: float16
2025-09-20 09:29:10,592 - loralab.core.unsloth_manager - INFO - Applied chat template: gemma3
2025-09-20 09:29:10,593 - loralab.datasets.dataset_loader - INFO - Loading dataset: gsm8k
2025-09-20 09:29:10,593 - loralab.datasets.dataset_loader - INFO - Fetching gsm8k from HuggingFace...
2025-09-20 09:29:14,032 - loralab.datasets.dataset_loader - INFO - Loaded 2000 training and 100 evaluation examples
2025-09-20 09:29:14,033 - loralab.evolution.evolutionary_trainer - INFO - 
================================================================================
2025-09-20 09:29:14,033 - loralab.evolution.evolutionary_trainer - INFO - STARTING EVOLUTIONARY OPTIMIZATION
2025-09-20 09:29:14,033 - loralab.evolution.evolutionary_trainer - INFO - ================================================================================
2025-09-20 09:29:14,034 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 0209a7c3)
2025-09-20 09:29:14,034 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr5e-05 (hash: 7b13c093)
2025-09-20 09:29:14,034 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: cc916834)
2025-09-20 09:29:14,034 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 3d608301)
2025-09-20 09:29:14,034 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr1e-04 (hash: 8054b9a9)
2025-09-20 09:29:14,034 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: f1ee4565)
2025-09-20 09:29:14,034 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr5e-05 (hash: baf5e86d)
2025-09-20 09:29:14,034 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr2e-04 (hash: c1bea809)
2025-09-20 09:29:14,034 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr1e-04 (hash: 239a06ae)
2025-09-20 09:29:14,034 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 0ba659fd)
2025-09-20 09:29:14,035 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr2e-04 (hash: a448aa76)
2025-09-20 09:29:14,035 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 2dec99bc)
2025-09-20 09:29:15,123 - loralab.core.unsloth_manager - INFO - LoRA variant created with Unsloth optimizations:
2025-09-20 09:29:15,123 - loralab.core.unsloth_manager - INFO -   Rank: 8, Alpha: 8 (multiplier: 1)
2025-09-20 09:29:15,124 - loralab.core.unsloth_manager - INFO -   Trainable params: 737,280 (0.27%)
2025-09-20 09:29:15,124 - loralab.core.unsloth_manager - INFO -   Gradient checkpointing: unsloth
2025-09-20 09:29:15,124 - loralab.core.unsloth_manager - INFO -   RSLoRA: True
2025-09-20 09:29:15,124 - loralab.evolution.evolutionary_trainer - INFO - Train data has 2000 total examples
2025-09-20 09:29:15,124 - loralab.evolution.evolutionary_trainer - INFO - Requesting 5 format examples
2025-09-20 09:29:15,124 - loralab.evolution.evolutionary_trainer - INFO - Actually got 5 format examples
2025-09-20 09:29:15,124 - loralab.evolution.evolutionary_trainer - INFO - Pre-training on format with 5 examples for 1 epochs
2025-09-20 09:29:15,124 - loralab.training.grpo_trainer - INFO - Pre-training model on format examples...
2025-09-20 09:29:15,163 - loralab.training.grpo_trainer - INFO - Pre-training configuration:
2025-09-20 09:29:15,163 - loralab.training.grpo_trainer - INFO -   - Examples: 5
2025-09-20 09:29:15,164 - loralab.training.grpo_trainer - INFO -   - Batch size: 1
2025-09-20 09:29:15,164 - loralab.training.grpo_trainer - INFO -   - Gradient accumulation: 2
2025-09-20 09:29:15,164 - loralab.training.grpo_trainer - INFO -   - Effective batch size: 2
2025-09-20 09:29:15,164 - loralab.training.grpo_trainer - INFO -   - Epochs: 1
2025-09-20 09:29:15,164 - loralab.training.grpo_trainer - INFO -   - Expected training steps: 5
2025-09-20 09:29:15,166 - loralab.training.grpo_trainer - INFO - Created pre-training dataset with 5 examples
2025-09-20 09:29:19,337 - loralab.training.grpo_trainer - INFO - Pre-training completed with final loss: 2.8983
2025-09-20 09:29:19,338 - loralab.training.grpo_trainer - INFO - Starting GRPO training for gen0_r8_lr1e-04
2025-09-20 10:09:08,842 - loralab.config.config_loader - INFO - Loaded configuration from loralab\config\gemma_config.yaml
2025-09-20 10:09:08,842 - loralab.utils.output_manager - INFO - Output manager initialized at: lora_runs_gemma\run_20250920_100908
2025-09-20 10:09:08,842 - loralab.evolution.evolutionary_trainer - INFO - Using unsloth backend
2025-09-20 10:09:08,845 - loralab.utils.output_manager - INFO - Config saved to: lora_runs_gemma\run_20250920_100908\config\config.yaml
2025-09-20 10:09:08,961 - loralab.core.unsloth_manager - INFO - Loading Unsloth model: unsloth/gemma-3-270m-it with none quantization
2025-09-20 10:09:08,961 - loralab.core.unsloth_manager - INFO - Using configured dtype: float16
2025-09-20 10:09:17,890 - loralab.core.unsloth_manager - INFO - Applied chat template: gemma3
2025-09-20 10:09:17,893 - loralab.datasets.dataset_loader - INFO - Loading dataset: gsm8k
2025-09-20 10:09:17,893 - loralab.datasets.dataset_loader - INFO - Fetching gsm8k from HuggingFace...
2025-09-20 10:09:22,370 - loralab.datasets.dataset_loader - INFO - Loaded 2000 training and 100 evaluation examples
2025-09-20 10:09:22,371 - loralab.evolution.evolutionary_trainer - INFO - 
================================================================================
2025-09-20 10:09:22,371 - loralab.evolution.evolutionary_trainer - INFO - STARTING EVOLUTIONARY OPTIMIZATION
2025-09-20 10:09:22,371 - loralab.evolution.evolutionary_trainer - INFO - ================================================================================
2025-09-20 10:09:22,371 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 0209a7c3)
2025-09-20 10:09:22,371 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr5e-05 (hash: 7b13c093)
2025-09-20 10:09:22,371 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: cc916834)
2025-09-20 10:09:22,371 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 3d608301)
2025-09-20 10:09:22,371 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr1e-04 (hash: 8054b9a9)
2025-09-20 10:09:22,371 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: f1ee4565)
2025-09-20 10:09:22,372 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr5e-05 (hash: baf5e86d)
2025-09-20 10:09:22,372 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr2e-04 (hash: c1bea809)
2025-09-20 10:09:22,372 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr1e-04 (hash: 239a06ae)
2025-09-20 10:09:22,372 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 0ba659fd)
2025-09-20 10:09:22,372 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr2e-04 (hash: a448aa76)
2025-09-20 10:09:22,372 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 2dec99bc)
2025-09-20 10:09:23,471 - loralab.core.unsloth_manager - INFO - LoRA variant created with Unsloth optimizations:
2025-09-20 10:09:23,472 - loralab.core.unsloth_manager - INFO -   Rank: 8, Alpha: 8 (multiplier: 1)
2025-09-20 10:09:23,472 - loralab.core.unsloth_manager - INFO -   Trainable params: 737,280 (0.27%)
2025-09-20 10:09:23,472 - loralab.core.unsloth_manager - INFO -   Gradient checkpointing: unsloth
2025-09-20 10:09:23,472 - loralab.core.unsloth_manager - INFO -   RSLoRA: True
2025-09-20 10:09:23,473 - loralab.evolution.evolutionary_trainer - INFO - Train data has 2000 total examples
2025-09-20 10:09:23,473 - loralab.evolution.evolutionary_trainer - INFO - Requesting 5 format examples
2025-09-20 10:09:23,473 - loralab.evolution.evolutionary_trainer - INFO - Actually got 5 format examples
2025-09-20 10:09:23,473 - loralab.evolution.evolutionary_trainer - INFO - Pre-training on format with 5 examples for 1 epochs
2025-09-20 10:09:23,473 - loralab.training.grpo_trainer - INFO - Pre-training model on format examples...
2025-09-20 10:09:23,520 - loralab.training.grpo_trainer - INFO - Pre-training configuration:
2025-09-20 10:09:23,520 - loralab.training.grpo_trainer - INFO -   - Examples: 5
2025-09-20 10:09:23,520 - loralab.training.grpo_trainer - INFO -   - Batch size: 1
2025-09-20 10:09:23,520 - loralab.training.grpo_trainer - INFO -   - Gradient accumulation: 2
2025-09-20 10:09:23,520 - loralab.training.grpo_trainer - INFO -   - Effective batch size: 2
2025-09-20 10:09:23,520 - loralab.training.grpo_trainer - INFO -   - Epochs: 1
2025-09-20 10:09:23,520 - loralab.training.grpo_trainer - INFO -   - Expected training steps: 5
2025-09-20 10:09:23,522 - loralab.training.grpo_trainer - INFO - Created pre-training dataset with 5 examples
2025-09-20 10:09:27,665 - loralab.training.grpo_trainer - INFO - Pre-training completed with final loss: 2.8983
2025-09-20 10:09:27,665 - loralab.training.grpo_trainer - INFO - Starting GRPO training for gen0_r8_lr1e-04
2025-09-20 10:12:01,260 - loralab.config.config_loader - INFO - Loaded configuration from loralab\config\gemma_config.yaml
2025-09-20 10:12:01,260 - loralab.utils.output_manager - INFO - Output manager initialized at: lora_runs_gemma\run_20250920_101201
2025-09-20 10:12:01,260 - loralab.evolution.evolutionary_trainer - INFO - Using unsloth backend
2025-09-20 10:12:01,263 - loralab.utils.output_manager - INFO - Config saved to: lora_runs_gemma\run_20250920_101201\config\config.yaml
2025-09-20 10:12:01,378 - loralab.core.unsloth_manager - INFO - Loading Unsloth model: unsloth/gemma-3-270m-it with none quantization
2025-09-20 10:12:01,379 - loralab.core.unsloth_manager - INFO - Using configured dtype: float16
2025-09-20 10:12:06,555 - loralab.core.unsloth_manager - INFO - Applied chat template: gemma3
2025-09-20 10:12:06,557 - loralab.datasets.dataset_loader - INFO - Loading dataset: gsm8k
2025-09-20 10:12:06,557 - loralab.datasets.dataset_loader - INFO - Fetching gsm8k from HuggingFace...
2025-09-20 10:12:10,082 - loralab.datasets.dataset_loader - INFO - Loaded 2000 training and 100 evaluation examples
2025-09-20 10:12:10,083 - loralab.evolution.evolutionary_trainer - INFO - 
================================================================================
2025-09-20 10:12:10,083 - loralab.evolution.evolutionary_trainer - INFO - STARTING EVOLUTIONARY OPTIMIZATION
2025-09-20 10:12:10,083 - loralab.evolution.evolutionary_trainer - INFO - ================================================================================
2025-09-20 10:12:10,083 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 0209a7c3)
2025-09-20 10:12:10,083 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr5e-05 (hash: 7b13c093)
2025-09-20 10:12:10,083 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: cc916834)
2025-09-20 10:12:10,083 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 3d608301)
2025-09-20 10:12:10,083 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr1e-04 (hash: 8054b9a9)
2025-09-20 10:12:10,084 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: f1ee4565)
2025-09-20 10:12:10,084 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr5e-05 (hash: baf5e86d)
2025-09-20 10:12:10,084 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr2e-04 (hash: c1bea809)
2025-09-20 10:12:10,084 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr1e-04 (hash: 239a06ae)
2025-09-20 10:12:10,084 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 0ba659fd)
2025-09-20 10:12:10,084 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr2e-04 (hash: a448aa76)
2025-09-20 10:12:10,084 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 2dec99bc)
2025-09-20 10:12:11,135 - loralab.core.unsloth_manager - INFO - LoRA variant created with Unsloth optimizations:
2025-09-20 10:12:11,136 - loralab.core.unsloth_manager - INFO -   Rank: 8, Alpha: 8 (multiplier: 1)
2025-09-20 10:12:11,137 - loralab.core.unsloth_manager - INFO -   Trainable params: 737,280 (0.27%)
2025-09-20 10:12:11,137 - loralab.core.unsloth_manager - INFO -   Gradient checkpointing: unsloth
2025-09-20 10:12:11,137 - loralab.core.unsloth_manager - INFO -   RSLoRA: True
2025-09-20 10:12:11,137 - loralab.evolution.evolutionary_trainer - INFO - Train data has 2000 total examples
2025-09-20 10:12:11,137 - loralab.evolution.evolutionary_trainer - INFO - Requesting 5 format examples
2025-09-20 10:12:11,137 - loralab.evolution.evolutionary_trainer - INFO - Actually got 5 format examples
2025-09-20 10:12:11,137 - loralab.evolution.evolutionary_trainer - INFO - Pre-training on format with 5 examples for 1 epochs
2025-09-20 10:12:11,137 - loralab.training.grpo_trainer - INFO - Pre-training model on format examples...
2025-09-20 10:12:11,176 - loralab.training.grpo_trainer - INFO - Pre-training configuration:
2025-09-20 10:12:11,177 - loralab.training.grpo_trainer - INFO -   - Examples: 5
2025-09-20 10:12:11,177 - loralab.training.grpo_trainer - INFO -   - Batch size: 1
2025-09-20 10:12:11,177 - loralab.training.grpo_trainer - INFO -   - Gradient accumulation: 2
2025-09-20 10:12:11,177 - loralab.training.grpo_trainer - INFO -   - Effective batch size: 2
2025-09-20 10:12:11,177 - loralab.training.grpo_trainer - INFO -   - Epochs: 1
2025-09-20 10:12:11,177 - loralab.training.grpo_trainer - INFO -   - Expected training steps: 5
2025-09-20 10:12:11,179 - loralab.training.grpo_trainer - INFO - Created pre-training dataset with 5 examples
2025-09-20 10:12:15,051 - loralab.training.grpo_trainer - INFO - Pre-training completed with final loss: 2.8983
2025-09-20 10:12:15,052 - loralab.training.grpo_trainer - INFO - Starting GRPO training for gen0_r8_lr1e-04
2025-09-20 10:14:12,184 - loralab.config.config_loader - INFO - Loaded configuration from loralab\config\gemma_config.yaml
2025-09-20 10:14:12,185 - loralab.utils.output_manager - INFO - Output manager initialized at: lora_runs_gemma\run_20250920_101412
2025-09-20 10:14:12,185 - loralab.evolution.evolutionary_trainer - INFO - Using unsloth backend
2025-09-20 10:14:12,188 - loralab.utils.output_manager - INFO - Config saved to: lora_runs_gemma\run_20250920_101412\config\config.yaml
2025-09-20 10:14:12,303 - loralab.core.unsloth_manager - INFO - Loading Unsloth model: unsloth/gemma-3-270m-it with none quantization
2025-09-20 10:14:12,303 - loralab.core.unsloth_manager - INFO - Using configured dtype: float16
2025-09-20 10:14:17,696 - loralab.core.unsloth_manager - INFO - Applied chat template: gemma3
2025-09-20 10:14:17,698 - loralab.datasets.dataset_loader - INFO - Loading dataset: gsm8k
2025-09-20 10:14:17,698 - loralab.datasets.dataset_loader - INFO - Fetching gsm8k from HuggingFace...
2025-09-20 10:14:21,195 - loralab.datasets.dataset_loader - INFO - Loaded 2000 training and 100 evaluation examples
2025-09-20 10:14:21,196 - loralab.evolution.evolutionary_trainer - INFO - 
================================================================================
2025-09-20 10:14:21,196 - loralab.evolution.evolutionary_trainer - INFO - STARTING EVOLUTIONARY OPTIMIZATION
2025-09-20 10:14:21,196 - loralab.evolution.evolutionary_trainer - INFO - ================================================================================
2025-09-20 10:14:21,196 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 0209a7c3)
2025-09-20 10:14:21,196 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr5e-05 (hash: 7b13c093)
2025-09-20 10:14:21,197 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: cc916834)
2025-09-20 10:14:21,197 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 3d608301)
2025-09-20 10:14:21,197 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr1e-04 (hash: 8054b9a9)
2025-09-20 10:14:21,197 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: f1ee4565)
2025-09-20 10:14:21,197 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr5e-05 (hash: baf5e86d)
2025-09-20 10:14:21,197 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr2e-04 (hash: c1bea809)
2025-09-20 10:14:21,197 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr1e-04 (hash: 239a06ae)
2025-09-20 10:14:21,197 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 0ba659fd)
2025-09-20 10:14:21,197 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr2e-04 (hash: a448aa76)
2025-09-20 10:14:21,197 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 2dec99bc)
2025-09-20 10:14:22,242 - loralab.core.unsloth_manager - INFO - LoRA variant created with Unsloth optimizations:
2025-09-20 10:14:22,242 - loralab.core.unsloth_manager - INFO -   Rank: 8, Alpha: 8 (multiplier: 1)
2025-09-20 10:14:22,242 - loralab.core.unsloth_manager - INFO -   Trainable params: 737,280 (0.27%)
2025-09-20 10:14:22,242 - loralab.core.unsloth_manager - INFO -   Gradient checkpointing: unsloth
2025-09-20 10:14:22,242 - loralab.core.unsloth_manager - INFO -   RSLoRA: True
2025-09-20 10:14:22,243 - loralab.evolution.evolutionary_trainer - INFO - Train data has 2000 total examples
2025-09-20 10:14:22,243 - loralab.evolution.evolutionary_trainer - INFO - Requesting 5 format examples
2025-09-20 10:14:22,243 - loralab.evolution.evolutionary_trainer - INFO - Actually got 5 format examples
2025-09-20 10:14:22,243 - loralab.evolution.evolutionary_trainer - INFO - Pre-training on format with 5 examples for 1 epochs
2025-09-20 10:14:22,243 - loralab.training.grpo_trainer - INFO - Pre-training model on format examples...
2025-09-20 10:14:22,285 - loralab.training.grpo_trainer - INFO - Pre-training configuration:
2025-09-20 10:14:22,285 - loralab.training.grpo_trainer - INFO -   - Examples: 5
2025-09-20 10:14:22,285 - loralab.training.grpo_trainer - INFO -   - Batch size: 1
2025-09-20 10:14:22,285 - loralab.training.grpo_trainer - INFO -   - Gradient accumulation: 2
2025-09-20 10:14:22,285 - loralab.training.grpo_trainer - INFO -   - Effective batch size: 2
2025-09-20 10:14:22,285 - loralab.training.grpo_trainer - INFO -   - Epochs: 1
2025-09-20 10:14:22,285 - loralab.training.grpo_trainer - INFO -   - Expected training steps: 5
2025-09-20 10:14:22,287 - loralab.training.grpo_trainer - INFO - Created pre-training dataset with 5 examples
2025-09-20 10:14:26,173 - loralab.training.grpo_trainer - INFO - Pre-training completed with final loss: 2.8991
2025-09-20 10:14:26,174 - loralab.training.grpo_trainer - INFO - Starting GRPO training for gen0_r8_lr1e-04
2025-09-20 10:14:38,468 - loralab.training.grpo_trainer - ERROR - CUDA error during GRPO training: Unsupported method call
  Explanation: Dynamo does not know how to trace method `__getitem__` of class `<unknown type>`
  Hint: Avoid calling `<unknown type>.__getitem__` in your code.
  Hint: Please report an issue to PyTorch.

  Developer debug context: call_method GetAttrVariable(ConstantVariable(float: 0.0), shape) __getitem__ (ConstantVariable(int: 1),) {}


from user code:
   File "C:\Users\Jake\Projects\lab\unsloth_compiled_cache\UnslothGRPOTrainer.py", line 308, in accumulate_chunk
    (chunk_grad_input,), (chunk_loss, (unscaled_loss, chunk_completion_length, chunk_mean_kl,)) = torch.func.grad_and_value(
  File "C:\Users\Jake\Projects\lab\.venv\Lib\site-packages\torch\_functorch\apis.py", line 441, in wrapper
    return eager_transforms.grad_and_value_impl(
  File "C:\Users\Jake\Projects\lab\.venv\Lib\site-packages\torch\_functorch\vmap.py", line 48, in fn
    return f(*args, **kwargs)
  File "C:\Users\Jake\Projects\lab\.venv\Lib\site-packages\torch\_functorch\eager_transforms.py", line 1365, in grad_and_value_impl
    output = func(*args, **kwargs)
  File "C:\Users\Jake\Projects\lab\unsloth_compiled_cache\UnslothGRPOTrainer.py", line 275, in compute_loss
    loss, completion_length, mean_kl = grpo_compute_loss(
  File "C:\Users\Jake\Projects\lab\unsloth_compiled_cache\UnslothGRPOTrainer.py", line 246, in grpo_compute_loss
    completion_length, mean_kl = masked_batch_mean(kl_i)
  File "C:\Users\Jake\Projects\lab\unsloth_compiled_cache\UnslothGRPOTrainer.py", line 240, in masked_batch_mean
    if x.shape[1] == 1:  # when importance_sampling_level == "sequence"

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"

2025-09-20 10:17:16,522 - loralab.config.config_loader - INFO - Loaded configuration from loralab\config\gemma_config.yaml
2025-09-20 10:17:16,523 - loralab.utils.output_manager - INFO - Output manager initialized at: lora_runs_gemma\run_20250920_101716
2025-09-20 10:17:16,523 - loralab.evolution.evolutionary_trainer - INFO - Using unsloth backend
2025-09-20 10:17:16,526 - loralab.utils.output_manager - INFO - Config saved to: lora_runs_gemma\run_20250920_101716\config\config.yaml
2025-09-20 10:17:16,643 - loralab.core.unsloth_manager - INFO - Loading Unsloth model: unsloth/gemma-3-270m-it with none quantization
2025-09-20 10:17:16,643 - loralab.core.unsloth_manager - INFO - Using configured dtype: float16
2025-09-20 10:17:21,868 - loralab.core.unsloth_manager - INFO - Applied chat template: gemma3
2025-09-20 10:17:21,870 - loralab.datasets.dataset_loader - INFO - Loading dataset: gsm8k
2025-09-20 10:17:21,871 - loralab.datasets.dataset_loader - INFO - Fetching gsm8k from HuggingFace...
2025-09-20 10:17:25,808 - loralab.datasets.dataset_loader - INFO - Loaded 2000 training and 100 evaluation examples
2025-09-20 10:17:25,809 - loralab.evolution.evolutionary_trainer - INFO - 
================================================================================
2025-09-20 10:17:25,809 - loralab.evolution.evolutionary_trainer - INFO - STARTING EVOLUTIONARY OPTIMIZATION
2025-09-20 10:17:25,809 - loralab.evolution.evolutionary_trainer - INFO - ================================================================================
2025-09-20 10:17:25,809 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 0209a7c3)
2025-09-20 10:17:25,810 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr5e-05 (hash: 7b13c093)
2025-09-20 10:17:25,810 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: cc916834)
2025-09-20 10:17:25,810 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 3d608301)
2025-09-20 10:17:25,810 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr1e-04 (hash: 8054b9a9)
2025-09-20 10:17:25,810 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: f1ee4565)
2025-09-20 10:17:25,810 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr5e-05 (hash: baf5e86d)
2025-09-20 10:17:25,810 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr2e-04 (hash: c1bea809)
2025-09-20 10:17:25,810 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr1e-04 (hash: 239a06ae)
2025-09-20 10:17:25,810 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 0ba659fd)
2025-09-20 10:17:25,810 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr2e-04 (hash: a448aa76)
2025-09-20 10:17:25,810 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 2dec99bc)
2025-09-20 10:17:26,976 - loralab.core.unsloth_manager - INFO - LoRA variant created with Unsloth optimizations:
2025-09-20 10:17:26,977 - loralab.core.unsloth_manager - INFO -   Rank: 8, Alpha: 8 (multiplier: 1)
2025-09-20 10:17:26,977 - loralab.core.unsloth_manager - INFO -   Trainable params: 737,280 (0.27%)
2025-09-20 10:17:26,977 - loralab.core.unsloth_manager - INFO -   Gradient checkpointing: unsloth
2025-09-20 10:17:26,977 - loralab.core.unsloth_manager - INFO -   RSLoRA: True
2025-09-20 10:17:26,977 - loralab.evolution.evolutionary_trainer - INFO - Train data has 2000 total examples
2025-09-20 10:17:26,977 - loralab.evolution.evolutionary_trainer - INFO - Requesting 5 format examples
2025-09-20 10:17:26,977 - loralab.evolution.evolutionary_trainer - INFO - Actually got 5 format examples
2025-09-20 10:17:26,977 - loralab.evolution.evolutionary_trainer - INFO - Pre-training on format with 5 examples for 1 epochs
2025-09-20 10:17:26,977 - loralab.training.grpo_trainer - INFO - Pre-training model on format examples...
2025-09-20 10:17:27,023 - loralab.training.grpo_trainer - INFO - Pre-training configuration:
2025-09-20 10:17:27,023 - loralab.training.grpo_trainer - INFO -   - Examples: 5
2025-09-20 10:17:27,023 - loralab.training.grpo_trainer - INFO -   - Batch size: 1
2025-09-20 10:17:27,023 - loralab.training.grpo_trainer - INFO -   - Gradient accumulation: 2
2025-09-20 10:17:27,023 - loralab.training.grpo_trainer - INFO -   - Effective batch size: 2
2025-09-20 10:17:27,024 - loralab.training.grpo_trainer - INFO -   - Epochs: 1
2025-09-20 10:17:27,024 - loralab.training.grpo_trainer - INFO -   - Expected training steps: 5
2025-09-20 10:17:27,025 - loralab.training.grpo_trainer - INFO - Created pre-training dataset with 5 examples
2025-09-20 10:17:31,202 - loralab.training.grpo_trainer - INFO - Pre-training completed with final loss: 2.8991
2025-09-20 10:17:31,202 - loralab.training.grpo_trainer - INFO - Starting GRPO training for gen0_r8_lr1e-04
2025-09-20 10:19:07,248 - loralab.config.config_loader - INFO - Loaded configuration from loralab\config\gemma_config.yaml
2025-09-20 10:19:07,249 - loralab.utils.output_manager - INFO - Output manager initialized at: lora_runs_gemma\run_20250920_101907
2025-09-20 10:19:07,249 - loralab.evolution.evolutionary_trainer - INFO - Using unsloth backend
2025-09-20 10:19:07,251 - loralab.utils.output_manager - INFO - Config saved to: lora_runs_gemma\run_20250920_101907\config\config.yaml
2025-09-20 10:19:07,371 - loralab.core.unsloth_manager - INFO - Loading Unsloth model: unsloth/gemma-3-270m-it with none quantization
2025-09-20 10:19:07,371 - loralab.core.unsloth_manager - INFO - Using configured dtype: float16
2025-09-20 10:19:12,762 - loralab.core.unsloth_manager - INFO - Applied chat template: gemma3
2025-09-20 10:19:12,764 - loralab.datasets.dataset_loader - INFO - Loading dataset: gsm8k
2025-09-20 10:19:12,764 - loralab.datasets.dataset_loader - INFO - Fetching gsm8k from HuggingFace...
2025-09-20 10:19:16,266 - loralab.datasets.dataset_loader - INFO - Loaded 2000 training and 100 evaluation examples
2025-09-20 10:19:16,267 - loralab.evolution.evolutionary_trainer - INFO - 
================================================================================
2025-09-20 10:19:16,267 - loralab.evolution.evolutionary_trainer - INFO - STARTING EVOLUTIONARY OPTIMIZATION
2025-09-20 10:19:16,268 - loralab.evolution.evolutionary_trainer - INFO - ================================================================================
2025-09-20 10:19:16,268 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 0209a7c3)
2025-09-20 10:19:16,268 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr5e-05 (hash: 7b13c093)
2025-09-20 10:19:16,268 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: cc916834)
2025-09-20 10:19:16,268 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 3d608301)
2025-09-20 10:19:16,268 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr1e-04 (hash: 8054b9a9)
2025-09-20 10:19:16,268 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: f1ee4565)
2025-09-20 10:19:16,268 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r32_lr5e-05 (hash: baf5e86d)
2025-09-20 10:19:16,268 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr2e-04 (hash: c1bea809)
2025-09-20 10:19:16,268 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r16_lr1e-04 (hash: 239a06ae)
2025-09-20 10:19:16,268 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r4_lr2e-04 (hash: 0ba659fd)
2025-09-20 10:19:16,268 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr2e-04 (hash: a448aa76)
2025-09-20 10:19:16,268 - loralab.core.lora_factory - INFO - Created unique variant: gen0_r8_lr1e-04 (hash: 2dec99bc)
2025-09-20 10:19:17,307 - loralab.core.unsloth_manager - INFO - LoRA variant created with Unsloth optimizations:
2025-09-20 10:19:17,307 - loralab.core.unsloth_manager - INFO -   Rank: 8, Alpha: 8 (multiplier: 1)
2025-09-20 10:19:17,307 - loralab.core.unsloth_manager - INFO -   Trainable params: 737,280 (0.27%)
2025-09-20 10:19:17,307 - loralab.core.unsloth_manager - INFO -   Gradient checkpointing: unsloth
2025-09-20 10:19:17,308 - loralab.core.unsloth_manager - INFO -   RSLoRA: True
2025-09-20 10:19:17,308 - loralab.evolution.evolutionary_trainer - INFO - Train data has 2000 total examples
2025-09-20 10:19:17,308 - loralab.evolution.evolutionary_trainer - INFO - Requesting 5 format examples
2025-09-20 10:19:17,308 - loralab.evolution.evolutionary_trainer - INFO - Actually got 5 format examples
2025-09-20 10:19:17,308 - loralab.evolution.evolutionary_trainer - INFO - Pre-training on format with 5 examples for 1 epochs
2025-09-20 10:19:17,308 - loralab.training.grpo_trainer - INFO - Pre-training model on format examples...
2025-09-20 10:19:17,350 - loralab.training.grpo_trainer - INFO - Pre-training configuration:
2025-09-20 10:19:17,350 - loralab.training.grpo_trainer - INFO -   - Examples: 5
2025-09-20 10:19:17,350 - loralab.training.grpo_trainer - INFO -   - Batch size: 1
2025-09-20 10:19:17,350 - loralab.training.grpo_trainer - INFO -   - Gradient accumulation: 2
2025-09-20 10:19:17,350 - loralab.training.grpo_trainer - INFO -   - Effective batch size: 2
2025-09-20 10:19:17,350 - loralab.training.grpo_trainer - INFO -   - Epochs: 1
2025-09-20 10:19:17,350 - loralab.training.grpo_trainer - INFO -   - Expected training steps: 5
2025-09-20 10:19:17,352 - loralab.training.grpo_trainer - INFO - Created pre-training dataset with 5 examples
2025-09-20 10:19:21,332 - loralab.training.grpo_trainer - INFO - Pre-training completed with final loss: 2.8983
2025-09-20 10:19:21,332 - loralab.training.grpo_trainer - INFO - Starting GRPO training for gen0_r8_lr1e-04
