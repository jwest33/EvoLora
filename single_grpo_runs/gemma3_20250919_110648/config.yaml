dataset:
  cache_dir: cache/datasets
  eval_size: 200
  max_seq_length: 512
  seed: 42
  sources:
  - gsm8k
  train_size: 1000
  use_cache: true
evolution:
  crossover_rate: 0.25
  generations: 10
  keep_top: 2
  mutation_rate: 0.35
  population_size: 4
grpo:
  enabled: true
  format_examples: 50
  max_completion_length: 512
  max_prompt_length: 512
  max_steps: 100
  num_generations: 4
  pre_train_format: true
  reasoning_end: </think>
  reasoning_start: <think>
  reward_weights:
    accuracy: 3.0
    format: 1.0
    reasoning: 2.0
  solution_end: </solution>
  solution_start: <solution>
  temperature: 0.8
logging:
  level: INFO
  save_history: true
  track_metrics:
  - accuracy
  - perplexity
  - fitness_score
  - rewards
lora_search_space:
  alpha_multiplier:
  - 1
  - 2
  dropout:
  - 0.0
  learning_rate:
  - 1e-4
  - 2e-4
  - 5e-4
  max_grad_norm:
  - 0.5
  - 1.0
  - 2.0
  rank:
  - 64
  - 128
  - 256
  target_modules:
  - q_proj
  - k_proj
  - v_proj
  - o_proj
  target_modules_preset:
  - standard
  - extended
  - full
  use_gradient_checkpointing: true
  use_rslora:
  - false
  - true
  warmup_ratio:
  - 0.0
  - 0.1
  - 0.2
  weight_decay:
  - 0.0
  - 0.01
  - 0.05
mode: self_supervised
model:
  backend: unsloth
  chat_template: gemma3
  device_map: cuda:0
  load_in_4bit: false
  load_in_8bit: false
  low_cpu_mem_usage: true
  max_seq_length: 2048
  path: unsloth/gemma-3-270m-it
  quantization: none
  torch_dtype: float16
  trust_remote_code: true
  type: transformers
  use_cache: false
output:
  base_dir: lora_runs_gemma3
  keep_runs: 5
  run_name: null
output_dir: evolved_adapters
quick_test:
  enabled: false
  eval_size: 20
  generations: 2
  population_size: 2
  train_size: 100
training:
  batch_size: 8
  bf16: false
  dataloader_num_workers: 0
  dataloader_pin_memory: true
  dataloader_prefetch_factor: 2
  epochs_per_variant: 1
  fp16: true
  gradient_accumulation_steps: 2
  gradient_checkpointing: false
  max_grad_norm: 1.0
  method: grpo
  warmup_ratio: 0.1
  weight_decay: 0.01
