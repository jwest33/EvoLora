# Configuration for code documentation generation task

# Base model for tool calling evaluation (optional)
# Uncomment and set this to your base model for testing
# base_model:
#   model_path: "C:\\models\\qwen2.5-3b-instruct-q4_k_m.gguf"
#
# === TASK FLOW EXPLANATION ===
#
# This system trains a small model (4B) to generate documentation for Python code
# using a larger model (30B) as a teacher. The process works as follows:
#
# 1. CHALLENGER (30B model) generates:
#    - Complex Python functions with varying difficulty
#    - "Perfect" documentation for each function (pseudo-labels)
#
# 2. SOLVER (4B model) learns to:
#    - Take Python functions as input
#    - Generate documentation similar to the Challenger's output
#    - Improve via LoRA adapter training
#
# Example Flow:
# -------------
# Challenger creates:     def fibonacci(n): ...
# Challenger documents:   "Calculates nth Fibonacci number recursively..."
# Solver learns:         Given fibonacci(), generate similar documentation
#
# The goal is to teach the smaller model to produce high-quality documentation
# without needing the computational resources of the larger model.

challenger:
  type: "llama_cpp"
  executable: "C:\\Users\\Jake\\llama.cpp\\build\\bin\\Release\\llama-server.exe"
  model_path: "C:\\models\\Qwen3-30B-A3B-Instruct-2507\\Qwen3-30B-A3B-Instruct-2507-Q8_0.gguf"
  gpu_layers: 20 # Reduced to save VRAM for the solver model
  port: 8080
  #context_size: 8192  # Reduced to save memory
  #parallel: 2  # Reduced parallel requests
  #batch_size: 512  # Batch size for prompt processing
  cpu_moe_layers: 20  # Number of MoE layers to offload to CPU (reduces VRAM usage)
  #cont_batching: true  # Enable continuous batching

solver:
  type: "transformers"
  model_name: "Qwen/Qwen3-4B-Instruct-2507"
  gguf_model_path: "C:\\models\\Qwen3-4B-Instruct-2507\\Qwen3-4B-Instruct-2507-Q8_0.gguf"
  device: "cuda"
  lora_config:
    rank: 16
    alpha: 32
    dropout: 0.1
    target_modules:
      - "q_proj"
      - "v_proj"
      - "k_proj"
      - "o_proj"
  quantization:
    enabled: true
    load_in_4bit: false
    load_in_8bit: true

task:
  type: "code_documentation"
  difficulty_progression: "adaptive"
  curriculum:
    initial_difficulty: 0.3
    target_success_rate: 0.7
  templates:
    # This template is used by CHALLENGER to generate Python functions
    # The Challenger will ALSO generate documentation for these functions
    # The Solver will then learn to generate similar documentation
    code_documentation: |
      Generate a complex Python function that requires detailed documentation.
      Difficulty level: {difficulty:.1f}

      The function should:
      - Have clear purpose but complex implementation
      - Include edge cases and error handling
      - Use type hints and advanced Python features
      - {difficulty_hints}

      Output only the function code:
      ```python

# === EXAMPLE OF GENERATED DATA ===
#
# Step 1 - Challenger generates Python function:
# -----------------------------------------------
# def merge_intervals(intervals: List[List[int]]) -> List[List[int]]:
#     if not intervals:
#         return []
#     intervals.sort(key=lambda x: x[0])
#     merged = [intervals[0]]
#     for current in intervals[1:]:
#         if current[0] <= merged[-1][1]:
#             merged[-1][1] = max(merged[-1][1], current[1])
#         else:
#             merged.append(current)
#     return merged
#
# Step 2 - Challenger generates ideal documentation:
# --------------------------------------------------
# """
# Merge overlapping intervals in a list.
#
# Takes a list of intervals represented as [start, end] pairs and merges
# all overlapping intervals into non-overlapping intervals.
#
# Args:
#     intervals: List of [start, end] integer pairs representing intervals
#
# Returns:
#     List of merged non-overlapping intervals sorted by start time
#
# Example:
#     >>> merge_intervals([[1,3],[2,6],[8,10],[15,18]])
#     [[1,6],[8,10],[15,18]]
# """
#
# Step 3 - Solver learns to generate similar documentation via LoRA training

training:
  learning_rate: 1e-5
  batch_size: 8
  num_rollouts: 4
  kl_penalty: 0.1
  clip_ratio: 0.2
  max_grad_norm: 1.0

evolution:
  generations: 50
  population_size: 10
  dataset_size_per_gen: 10  # Reduced for faster iteration during development
  bootstrap_size: 10  # Smaller initial dataset for quick baseline
  eval_ratio: 0.2

output_dir: "experiments/doc_gen_v1"
