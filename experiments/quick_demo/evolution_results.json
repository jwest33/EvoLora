{
  "total_generations": 2,
  "best_score": 0.5921333782062813,
  "history": [
    {
      "generation": 1,
      "metrics": {
        "loss": -0.08796732500195503,
        "policy_loss": -0.08796732500195503,
        "kl_loss": 0,
        "eval_score": 0.5921333782062813,
        "task_quality": 0.48,
        "train_time": 2788.0504422187805,
        "num_train_tasks": 8,
        "num_eval_tasks": 2
      },
      "timestamp": "2025-09-16T18:16:33.470248"
    }
  ],
  "config": {
    "challenger": {
      "cpu_moe_layers": 20,
      "executable": "C:\\Users\\Jake\\llama.cpp\\build\\bin\\Release\\llama-server.exe",
      "gpu_layers": 20,
      "model_path": "C:\\models\\Qwen3-30B-A3B-Thinking-2507\\Qwen3-30B-A3B-Thinking-2507-Q8_0.gguf",
      "port": 8080,
      "type": "llama_cpp",
      "use_direct": true
    },
    "evolution": {
      "bootstrap_size": 10,
      "dataset_size_per_gen": 10,
      "eval_ratio": 0.2,
      "generations": 5,
      "population_size": 10
    },
    "output_dir": "experiments/quick_demo",
    "solver": {
      "device": "cuda",
      "lora_config": {
        "alpha": 32,
        "dropout": 0.1,
        "rank": 16,
        "target_modules": [
          "q_proj",
          "v_proj",
          "k_proj",
          "o_proj"
        ]
      },
      "model_name": "Qwen/Qwen3-4B-Instruct-2507",
      "quantization": {
        "enabled": true,
        "load_in_4bit": false,
        "load_in_8bit": true
      },
      "type": "transformers"
    },
    "task": {
      "curriculum": {
        "initial_difficulty": 0.3,
        "target_success_rate": 0.7
      },
      "difficulty_progression": "adaptive",
      "templates": {
        "code_documentation": "Generate a complex Python function that requires detailed documentation.\nDifficulty level: {difficulty:.1f}\n\nThe function should:\n- Have clear purpose but complex implementation\n- Include edge cases and error handling\n- Use type hints and advanced Python features\n- {difficulty_hints}\n\nOutput only the function code:\n```python\n"
      },
      "type": "code_documentation"
    },
    "training": {
      "batch_size": 8,
      "clip_ratio": 0.2,
      "kl_penalty": 0.1,
      "learning_rate": "1e-5",
      "max_grad_norm": 1.0,
      "num_rollouts": 4
    }
  },
  "timestamp": "2025-09-16T18:33:29.991242"
}