2025-09-21 07:12:42,231 - __main__ - INFO - Loading GSM8K dataset...
2025-09-21 07:12:42,231 - loralab.datasets.gsm8k_handler - INFO - Loading GSM8K dataset...
2025-09-21 07:12:46,019 - loralab.datasets.gsm8k_handler - INFO - GSM8K loaded: 7473 train, 131 test examples
2025-09-21 07:12:46,022 - __main__ - INFO - Loading Challenger: Qwen3-4B-Instruct-2507
2025-09-21 07:12:48,002 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-21 07:15:11,893 - __main__ - INFO - Loading GSM8K dataset...
2025-09-21 07:15:11,893 - loralab.datasets.gsm8k_handler - INFO - Loading GSM8K dataset...
2025-09-21 07:15:15,818 - loralab.datasets.gsm8k_handler - INFO - GSM8K loaded: 7473 train, 131 test examples
2025-09-21 07:15:15,822 - __main__ - INFO - Loading Challenger: Qwen3-4B-Instruct-2507
2025-09-21 07:15:17,595 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-21 07:15:22,877 - __main__ - INFO - Challenger loaded: 66,060,288 trainable params
2025-09-21 07:15:22,878 - __main__ - INFO - Pre-fine-tuning Challenger for format...
2025-09-21 07:15:23,053 - datasets.arrow_dataset - WARNING - num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.
